{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DineshThumma9/miniature-octo-memory/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a27f42450ca6690",
      "metadata": {
        "id": "2a27f42450ca6690"
      },
      "source": [
        "Download pdf using request and reuse if already exists"
      ]
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:01:30.870223Z",
          "start_time": "2025-05-15T12:01:30.859397Z"
        },
        "id": "initial_id"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "pdf_path = \"human-nutrition-text.pdf\"\n",
        "\n",
        "if not os.path.exists(pdf_path):\n",
        "    print(f\"[INFO] file doesnt exist , downloading\")\n",
        "    url = \"https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf\"\n",
        "    filename = pdf_path\n",
        "\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        with open(filename,\"wb\") as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"[INFO] The file has been downloaded and saved as {filename}\")\n",
        "    else:\n",
        "        print(f\"[INFO] Failed to download the file .Status Code : {response.status_code}\")\n",
        "else:\n",
        "    print(f\"File Exists\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "2abca565b0d02a12",
      "metadata": {
        "id": "2abca565b0d02a12"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "feff964b2d1de0ca",
      "metadata": {
        "id": "feff964b2d1de0ca"
      },
      "source": [
        "#Format Pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pymupdf"
      ],
      "metadata": {
        "id": "ktL5hnY15nDM"
      },
      "id": "ktL5hnY15nDM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "16db3d0449989589",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:02:10.629063Z",
          "start_time": "2025-05-15T12:02:10.343488Z"
        },
        "id": "16db3d0449989589"
      },
      "source": [
        "\n",
        "import  pymupdf\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def text_formatter(text:str) -> str:\n",
        "    cleaned_text = text.replace(\"\\n\",\" \").strip()\n",
        "    return cleaned_text\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "f039bbf46d42a7fa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:02:16.039857Z",
          "start_time": "2025-05-15T12:02:14.138672Z"
        },
        "id": "f039bbf46d42a7fa"
      },
      "source": [
        "\n",
        "def open_and_read_pdf(pdf_path:str)->list[dict]:\n",
        "    docs = pymupdf.open(pdf_path)\n",
        "    pages_and_text = []\n",
        "    for page_no , page in tqdm(enumerate(docs)):\n",
        "        text = page.get_text()\n",
        "        text = text_formatter(text=text)\n",
        "        pages_and_text.append({\n",
        "            \"page_number\" : page_no-41,\n",
        "            \"page_char_cnt\" : len(text),\n",
        "            \"page_word_cnt\" : len(text.split(\" \")),\n",
        "            \"page_sentence_count_raw\" : len(text.split(\". \")),\n",
        "            \"page_token_cnt\" : len(text)/4,\n",
        "            \"text\" : text\n",
        "\n",
        "        }\n",
        "        )\n",
        "\n",
        "    return pages_and_text\n",
        "\n",
        "\n",
        "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
        "pages_and_texts[:2]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "6606480e0808584",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:02:56.963167Z",
          "start_time": "2025-05-15T12:02:56.955632Z"
        },
        "id": "6606480e0808584"
      },
      "source": [
        "import  random\n",
        "\n",
        "random.sample(pages_and_texts,k=3)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c5b0b6ae1cbff840",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:05.434228Z",
          "start_time": "2025-05-15T12:03:04.507143Z"
        },
        "id": "c5b0b6ae1cbff840"
      },
      "source": [
        "import  pandas as  pd\n",
        "\n",
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.head()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "f0f5291f244e531f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:05.487094Z",
          "start_time": "2025-05-15T12:03:05.460934Z"
        },
        "id": "f0f5291f244e531f"
      },
      "source": [
        "df.describe().round(2)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "1d8f8dbe50d8d180",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:15.604652Z",
          "start_time": "2025-05-15T12:03:05.606132Z"
        },
        "id": "1d8f8dbe50d8d180"
      },
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "doc = nlp(\"This is a sentence. This another sentence. I like elephants\")\n",
        "assert len(list(doc.sents)) == 3\n",
        "list(doc.sents)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "5501bb0fa5bc14e5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:23.731266Z",
          "start_time": "2025-05-15T12:03:15.691902Z"
        },
        "id": "5501bb0fa5bc14e5"
      },
      "source": [
        "\n",
        "for item in tqdm(pages_and_texts):\n",
        "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
        "\n",
        "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"] ]\n",
        "\n",
        "    item[\"page_sentence_cnt_spacy\"] = len(item[\"sentences\"])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "3aa3ef1996ba8c79",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:23.837066Z",
          "start_time": "2025-05-15T12:03:23.817105Z"
        },
        "id": "3aa3ef1996ba8c79"
      },
      "source": [
        "random.sample(pages_and_texts,k=2)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "3a1db191b8b55f72",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:24.136145Z",
          "start_time": "2025-05-15T12:03:24.063795Z"
        },
        "id": "3a1db191b8b55f72"
      },
      "source": [
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.describe().round(2)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "70b8b089673321a1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:24.329886Z",
          "start_time": "2025-05-15T12:03:24.311296Z"
        },
        "id": "70b8b089673321a1"
      },
      "source": [
        "\n",
        "num_sentence_chunck_size = 15\n",
        "\n",
        "\n",
        "def split_list(\n",
        "        input_list : list[str],\n",
        "        slice_size : int = num_sentence_chunck_size\n",
        "\n",
        ") -> list[list[str]]:\n",
        "\n",
        "    return [input_list[i:i+slice_size] for i in range(0,len(input_list) , slice_size) ]\n",
        "\n",
        "\n",
        "\n",
        "test_list = list(range(25))\n",
        "split_list(test_list)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "2118cd587085702e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:24.403830Z",
          "start_time": "2025-05-15T12:03:24.359469Z"
        },
        "id": "2118cd587085702e"
      },
      "source": [
        "\n",
        "\n",
        "for item in tqdm(pages_and_texts):\n",
        "    item[\"sentence_chucks\"]  = split_list(\n",
        "        input_list= item[\"sentences\"],\n",
        "        slice_size=num_sentence_chunck_size\n",
        "    )\n",
        "\n",
        "    item[\"num_chunks\"] = len(item[\"sentence_chucks\"])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "47658036301e0246",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:24.590630Z",
          "start_time": "2025-05-15T12:03:24.573640Z"
        },
        "id": "47658036301e0246"
      },
      "source": [
        "random.sample(pages_and_texts,k=1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "e33e146102913869",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:24.822540Z",
          "start_time": "2025-05-15T12:03:24.752293Z"
        },
        "id": "e33e146102913869"
      },
      "source": [
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.describe().round(2)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "d7d29a8e4b50ed93",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:25.551475Z",
          "start_time": "2025-05-15T12:03:25.021070Z"
        },
        "id": "d7d29a8e4b50ed93"
      },
      "source": [
        "import re\n",
        "\n",
        "pages_and_chuncks = []\n",
        "\n",
        "for item in tqdm(pages_and_texts):\n",
        "    for sentence_chunck in item[\"sentence_chucks\"]:\n",
        "\n",
        "        chunck_dic={}\n",
        "        chunck_dic[\"page_no\"]  = item[\"page_number\"]\n",
        "\n",
        "        joined_sentence_chunck = \"\".join(sentence_chunck).replace(\"  \",\" \").strip()\n",
        "        joined_sentence_chunck = re.sub(r'\\.([A-Z])' ,r' .\\1' , joined_sentence_chunck)\n",
        "\n",
        "\n",
        "        chunck_dic[\"sentence_chuck\"] = joined_sentence_chunck\n",
        "\n",
        "        chunck_dic[\"chunck_char_count\"] = len(joined_sentence_chunck)\n",
        "        chunck_dic[\"chunck_word_count\"]  = len([word  for word in joined_sentence_chunck.split(\" \")])\n",
        "        chunck_dic[\"chunck_token_count\"] = len(joined_sentence_chunck)/4\n",
        "\n",
        "        pages_and_chuncks.append(chunck_dic)\n",
        "\n",
        "len(pages_and_chuncks)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "976340840b91250d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:26.226899Z",
          "start_time": "2025-05-15T12:03:26.210332Z"
        },
        "id": "976340840b91250d"
      },
      "source": [
        "random.sample(pages_and_chuncks,k=3)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "ae87748bc4ec5119",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:26.430815Z",
          "start_time": "2025-05-15T12:03:26.376156Z"
        },
        "id": "ae87748bc4ec5119"
      },
      "source": [
        "df = pd.DataFrame(pages_and_chuncks)\n",
        "df.describe().round(2)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "256f7985c0f4e95d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:26.612772Z",
          "start_time": "2025-05-15T12:03:26.588898Z"
        },
        "id": "256f7985c0f4e95d"
      },
      "source": [
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "3a0fdadb633a034a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:26.789795Z",
          "start_time": "2025-05-15T12:03:26.764207Z"
        },
        "id": "3a0fdadb633a034a"
      },
      "source": [
        "min_token_length=30\n",
        "for row in df[df[\"chunck_token_count\"] <= min_token_length].sample(5).iterrows():\n",
        "    print(f'Chunck token count:{row[1][\"chunck_token_count\"]} | Text : {row[1][\"sentence_chuck\"]}')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "80cdf8312b712b03",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:27.114401Z",
          "start_time": "2025-05-15T12:03:27.089307Z"
        },
        "id": "80cdf8312b712b03"
      },
      "source": [
        "pages_and_chuncks_over_min_token_len = df[df[\"chunck_token_count\"] > min_token_length].to_dict(orient =\"records\")\n",
        "pages_and_chuncks_over_min_token_len[:2]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "3abb77e19fbff3e4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:03:27.328500Z",
          "start_time": "2025-05-15T12:03:27.308593Z"
        },
        "id": "3abb77e19fbff3e4"
      },
      "source": [
        "random.sample(pages_and_chuncks_over_min_token_len,k=4)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c8c2d8c47ec66f85",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:04:06.501883Z",
          "start_time": "2025-05-15T12:03:27.478310Z"
        },
        "id": "c8c2d8c47ec66f85"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "embedding_model = SentenceTransformer(\n",
        "\n",
        "    model_name_or_path=\"all-mpnet-base-v2\",\n",
        "    device=\"cpu\"\n",
        ")\n",
        "\n",
        "sentence = [\n",
        " \"How does it works\",\n",
        "    \"Capture meaning in numeric reprsesenation\"\n",
        "]\n",
        "\n",
        "embeddinngs = embedding_model.encode(sentence)\n",
        "embedding_dict = dict(\n",
        "    zip(sentence ,embeddinngs)\n",
        ")\n",
        "\n",
        "for sentence,embeddinngs in embedding_dict.items():\n",
        "    print(f\"Sentence  : {sentence}\")\n",
        "    print(f\"Embeddings:{embeddinngs}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c5bd9c5d8f5b15b3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:04:06.566892Z",
          "start_time": "2025-05-15T12:04:06.550173Z"
        },
        "id": "c5bd9c5d8f5b15b3"
      },
      "source": [
        "embeddinngs[1].shape"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "e3dd721b09e3fa1a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:04:06.915049Z",
          "start_time": "2025-05-15T12:04:06.645900Z"
        },
        "id": "e3dd721b09e3fa1a"
      },
      "source": [
        "embeddinng = embedding_model.encode(\"Hi\")\n",
        "embeddinng1 = embedding_model.encode(\"Hello\")\n",
        "print(embeddinng)\n",
        "print(embeddinng1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "ee13f72d5db7c072",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:04:06.988172Z",
          "start_time": "2025-05-15T12:04:06.976056Z"
        },
        "id": "ee13f72d5db7c072"
      },
      "source": [
        "# %%time\n",
        "#\n",
        "#\n",
        "# embedding_model.to(\"cpu\")\n",
        "#\n",
        "# for item in tqdm(pages_and_chuncks_over_min_token_len):\n",
        "#     item[\"embedding\"] = embedding_model.encode(item[\"sentence_chuck\"])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "a990b3d16d8914c1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:06:48.012734Z",
          "start_time": "2025-05-15T12:04:07.014558Z"
        },
        "id": "a990b3d16d8914c1"
      },
      "source": [
        "%%time\n",
        "\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.version.cuda)\n",
        "print(torch.backends.cudnn.version())  # Should return your CUDA version\n",
        "print(torch.cuda.get_device_name(0))  # Should return your GPU name (if available)\n",
        "embedding_model.to(\"cuda\")\n",
        "\n",
        "for item in tqdm(pages_and_chuncks_over_min_token_len):\n",
        "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chuck\"])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "f23edba5-c8d2-4472-8d3f-d611c1c3af19",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:06:48.474022Z",
          "start_time": "2025-05-15T12:06:48.452413Z"
        },
        "id": "f23edba5-c8d2-4472-8d3f-d611c1c3af19"
      },
      "source": [
        "%%time\n",
        "\n",
        "text_chuncks = [item[\"sentence_chuck\"] for item in pages_and_chuncks_over_min_token_len]\n",
        "text_chuncks[419]\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:06:48.579463Z",
          "start_time": "2025-05-15T12:06:48.568213Z"
        },
        "id": "c7cfba91e1beb078"
      },
      "cell_type": "code",
      "source": [
        "len(text_chuncks)\n"
      ],
      "id": "c7cfba91e1beb078",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:23.503726Z",
          "start_time": "2025-05-15T12:06:48.625186Z"
        },
        "id": "51931c48a22b125f"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "text_chuncks_embeddings = embedding_model.encode(\n",
        "    text_chuncks,\n",
        "    batch_size = 32,\n",
        "    convert_to_tensor = True\n",
        ")\n",
        "\n",
        "text_chuncks_embeddings"
      ],
      "id": "51931c48a22b125f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:40.290572Z",
          "start_time": "2025-05-15T12:11:24.051867Z"
        },
        "id": "c1de1cf91c6677e3"
      },
      "cell_type": "code",
      "source": [
        "text_chuncks_and_embeddings_df = pd.DataFrame(\n",
        "    pages_and_chuncks_over_min_token_len\n",
        ")\n",
        "embeddings_df_save_path = \"text_chuncks_and_embeddings_df.csv\"\n",
        "text_chuncks_and_embeddings_df.to_csv(embeddings_df_save_path,index = False)\n"
      ],
      "id": "c1de1cf91c6677e3",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:40.647249Z",
          "start_time": "2025-05-15T12:11:40.307675Z"
        },
        "id": "2c32a30e6e2553d7"
      },
      "cell_type": "code",
      "source": [
        "text_chuncks_and_embeddings_df_load = pd.read_csv(embeddings_df_save_path)\n",
        "text_chuncks_and_embeddings_df_load.head()"
      ],
      "id": "2c32a30e6e2553d7",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:41.446068Z",
          "start_time": "2025-05-15T12:11:41.441299Z"
        },
        "id": "bec6d726ae8b7cc5"
      },
      "cell_type": "code",
      "source": [],
      "id": "bec6d726ae8b7cc5",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:41.534632Z",
          "start_time": "2025-05-15T12:11:41.528953Z"
        },
        "id": "618da4c2fc4ee95c"
      },
      "cell_type": "code",
      "source": [
        "print(type(text_chuncks_and_embeddings_df[\"embedding\"][0]))"
      ],
      "id": "618da4c2fc4ee95c",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:42.232764Z",
          "start_time": "2025-05-15T12:11:41.594005Z"
        },
        "id": "741b227c7e5aa1ea"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "text_chuncks_and_embeddings_df = pd.read_csv(embeddings_df_save_path)\n",
        "\n",
        "\n",
        "print(type(text_chuncks_and_embeddings_df[\"embedding\"][0]))\n",
        "# Ensure the column has no NaN or invalid values\n",
        "\n",
        "\n",
        "text_chuncks_and_embeddings_df[\"embedding\"] = text_chuncks_and_embeddings_df[\"embedding\"].fillna(\"[]\")\n",
        "\n",
        "text_chuncks_and_embeddings_df[\"embedding\"] = text_chuncks_and_embeddings_df[\"embedding\"].apply(lambda x : np.fromstring(x.strip(\"[]\"),sep = \" \"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "pages_and_chuncks = text_chuncks_and_embeddings_df.to_dict(orient = \"records\")\n",
        "\n",
        "\n",
        "\n",
        "text_chuncks_and_embeddings_df\n"
      ],
      "id": "741b227c7e5aa1ea",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:42.343451Z",
          "start_time": "2025-05-15T12:11:42.317330Z"
        },
        "id": "b540feb845f51cce"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Check the shapes of all embeddings\n",
        "embedding_shapes = [embedding.shape for embedding in text_chuncks_and_embeddings_df[\"embedding\"]]\n",
        "\n",
        "# Find the maximum shape\n",
        "max_length = max(shape[0] for shape in embedding_shapes)\n",
        "\n",
        "# Pad or truncate embeddings to the maximum length\n",
        "def pad_or_truncate(embedding, max_length):\n",
        "    if len(embedding) < max_length:\n",
        "        return np.pad(embedding, (0, max_length - len(embedding)), mode='constant')\n",
        "    return embedding[:max_length]\n",
        "\n",
        "text_chuncks_and_embeddings_df[\"embedding\"] = text_chuncks_and_embeddings_df[\"embedding\"].apply(\n",
        "    lambda x: pad_or_truncate(x, max_length)\n",
        ")\n",
        "\n",
        "# Stack embeddings\n",
        "embeddings = torch.tensor(np.stack(text_chuncks_and_embeddings_df[\"embedding\"].to_list(), axis=0))\n",
        "\n",
        "\n",
        "\n",
        "embeddings"
      ],
      "id": "b540feb845f51cce",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:42.403787Z",
          "start_time": "2025-05-15T12:11:42.398204Z"
        },
        "id": "fd7a927ac528aaa2"
      },
      "cell_type": "code",
      "source": [
        "print(type(embeddings))\n",
        "print(type(embeddings[6]))\n"
      ],
      "id": "fd7a927ac528aaa2",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:42.699110Z",
          "start_time": "2025-05-15T12:11:42.692736Z"
        },
        "id": "1b0f09d176eaa6fd"
      },
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "id": "1b0f09d176eaa6fd",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:43.854757Z",
          "start_time": "2025-05-15T12:11:42.720181Z"
        },
        "id": "9f7b1a2e8cca2fe3"
      },
      "cell_type": "code",
      "source": [
        "from sentence_transformers import  util\n",
        "\n",
        "embeddings_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\" , device = device)\n",
        "\n",
        "\n",
        "query = \"Good Food for Proteins\"\n",
        "print(f\"Query:{query}\")\n",
        "query_embeddings = embedding_model.encode(query,convert_to_tensor = True)\n",
        "# Ensure both tensors have the same dtype\n",
        "query_embeddings = query_embeddings.to(dtype=torch.float32)\n",
        "query_embeddings = query_embeddings.to(device = device)\n",
        "embeddings = embeddings.to(dtype=torch.float32)\n",
        "embeddings = embeddings.to(device=device)\n",
        "from time import perf_counter as timer\n",
        "\n",
        "start_time = timer()\n",
        "dot_scores = util.dot_score(a=query_embeddings , b = embeddings)[0]\n",
        "end_time = timer()\n",
        "\n",
        "\n",
        "print(f\"[INFO] Time Taken to get scores on {len(embeddings)} embeddings : {end_time-start_time:.5f} seconds.\")\n",
        "\n",
        "\n",
        "top_results_dot_product = torch.topk(dot_scores,k=5)\n",
        "top_results_dot_product\n",
        "\n"
      ],
      "id": "9f7b1a2e8cca2fe3",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:44.423174Z",
          "start_time": "2025-05-15T12:11:44.413645Z"
        },
        "id": "31f7f7c815997285"
      },
      "cell_type": "code",
      "source": [
        "print(type(tuple(top_results_dot_product)))\n",
        "\n",
        "top_results_dot_product =  tuple(top_results_dot_product)\n",
        "\n",
        "print(top_results_dot_product)\n",
        "\n",
        "print(top_results_dot_product[1])\n"
      ],
      "id": "31f7f7c815997285",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:44.441590Z",
          "start_time": "2025-05-15T12:11:44.433898Z"
        },
        "id": "e8f2d63f45f20bbf"
      },
      "cell_type": "code",
      "source": [
        "indexes = list(top_results_dot_product[1])\n",
        "\n",
        "for idx in  indexes:\n",
        "    print(pages_and_chuncks[idx][\"sentence_chuck\"])\n",
        "    print()"
      ],
      "id": "e8f2d63f45f20bbf",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:44.457984Z",
          "start_time": "2025-05-15T12:11:44.453134Z"
        },
        "id": "1a9d1a61879c5fda"
      },
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "def print_wrapped(text , wrap_lenth = 80):\n",
        "    wrapped_text = textwrap.fill(text,wrap_lenth)\n",
        "    print(wrapped_text)\n",
        "\n",
        "\n"
      ],
      "id": "1a9d1a61879c5fda",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:48.357017Z",
          "start_time": "2025-05-15T12:11:48.335891Z"
        },
        "id": "87a31bbf48863c2f"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for score, idx in zip(scores, indexes):\n",
        "    chunk = pages_and_chuncks[idx]\n",
        "    print_wrapped(f\"Page Score   : {score}\")\n",
        "    print_wrapped(f\"Content      : {chunk['sentence_chuck']}\")\n",
        "    print_wrapped(f\"Page Number  : {chunk['page_no']}\")\n",
        "    print()\n"
      ],
      "id": "87a31bbf48863c2f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:49.396043Z",
          "start_time": "2025-05-15T12:11:48.706031Z"
        },
        "id": "200cf0c618b33eed"
      },
      "cell_type": "code",
      "source": [
        "import pymupdf\n",
        "\n",
        "pdf_path = \"human-nutrition-text.pdf\"\n",
        "doc = pymupdf.open(pdf_path)\n",
        "page = doc.load_page(7)\n",
        "\n",
        "\n",
        "img = page.get_pixmap(dpi=300)\n",
        "\n",
        "\n",
        "img.save(\"output_filename.png\")\n",
        "\n",
        "img_array = np.frombuffer(img.samples_mv,\n",
        "                          dtype = np.uint8).reshape(img.h,img.w,img.n)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(13,10))\n",
        "plt.imshow(img_array)\n",
        "plt.title(f\"Query: {query} | Most Relevent page: \")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "id": "200cf0c618b33eed",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:49.478106Z",
          "start_time": "2025-05-15T12:11:49.469960Z"
        },
        "id": "5c44e3d22420da21"
      },
      "cell_type": "code",
      "source": [
        "def dot_product(vec1,vec2):\n",
        "    return torch.dot(vec1,vec2)\n",
        "\n",
        "\n",
        "def cosine_sim(vec1,vec2):\n",
        "    dot_product  = torch.dot(vec1,vec2)\n",
        "    norm1 = torch.sqrt(torch.sum(vec1**2))\n",
        "    norm2 = torch.sqrt(torch.sum(vec2**2))\n",
        "    return dot_product/(norm1*norm2)\n",
        "\n",
        "vec1 = torch.tensor([1,2,3] , dtype=torch.float32)\n",
        "vec2 = torch.tensor([1,2,3] , dtype=torch.float32)\n",
        "vec3 = torch.tensor([1,2,3] , dtype=torch.float32)\n",
        "vec4 = torch.tensor([1,2,3] , dtype=torch.float32)"
      ],
      "id": "5c44e3d22420da21",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:11:49.647416Z",
          "start_time": "2025-05-15T12:11:49.637618Z"
        },
        "id": "9d38a1f328ac3ae0"
      },
      "cell_type": "code",
      "source": [
        "def retrive_relevent_resources(\n",
        "        query:str,\n",
        "        embeddings:torch.tensor,\n",
        "        model:SentenceTransformer = embeddings_model,\n",
        "        n_resources_to_return : int = 5,\n",
        "        print_time:bool = True\n",
        "):\n",
        "\n",
        "    query_embeddings = model.encode(query,convert_to_tensor=True)\n",
        "\n",
        "    start_time = timer()\n",
        "    dot_score = util.dot_score(query_embeddings,embeddings)[0]\n",
        "    end_time = timer()\n",
        "\n",
        "\n",
        "    if print_time:\n",
        "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings:{end_time-start_time:.5f} seconds\")\n",
        "\n",
        "\n",
        "    scores1,indices = torch.topk(\n",
        "        input=dot_scores,\n",
        "        k=n_resources_to_return\n",
        "    )\n",
        "\n",
        "\n",
        "    return scores1,indices\n",
        "\n",
        "\n",
        "def print_top_results_and_scores(\n",
        "        query:str,\n",
        "        embeddings:torch.tensor,\n",
        "        pages_and_chuncks:list[dict]=pages_and_chuncks,\n",
        "\n",
        "):\n",
        "    indexes = list(top_results_dot_product[1])\n",
        "    scores = list(top_results_dot_product[0])\n",
        "    for score ,idx in  zip(scores,indexes):\n",
        "        print_wrapped(f\"Page Score : {score}\")\n",
        "        print_wrapped(pages_and_chuncks[idx][\"sentence_chuck\"])\n",
        "        print_wrapped(f\"Page Number : {pages_and_chuncks[idx]['page_no']}\")\n",
        "        print()\n",
        "\n",
        "\n"
      ],
      "id": "9d38a1f328ac3ae0",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate\n",
        "!pip install bitsandbytes\n"
      ],
      "metadata": {
        "id": "nXtunFRI7xFr"
      },
      "id": "nXtunFRI7xFr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()\n"
      ],
      "metadata": {
        "id": "xNtG9hNq9oJJ"
      },
      "id": "xNtG9hNq9oJJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:12:58.075641Z",
          "start_time": "2025-05-15T12:11:49.939263Z"
        },
        "id": "db449e13fd23ffda"
      },
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
        "from transformers.utils import is_flash_attn_2_available\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "quantize_config  = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                                      bnb_4bit_compute_type=torch.float16)\n",
        "\n",
        "\n",
        "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability >= 8):\n",
        "    attn_impl = \"flash_attention_2\"\n",
        "else:\n",
        "    attn_impl = \"sdpa\"\n",
        "\n",
        "\n",
        "\n",
        "model_id = \"google/gemma-3-4b-it\"\n",
        "snapshot_download(repo_id=model_id, repo_type=\"model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id)\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "    pretrained_model_name_or_path=model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage = False,\n",
        "    attn_implementation = attn_impl\n",
        ")\n",
        "\n",
        "\n",
        "llm_model.to(\"cuda\")\n",
        "\n",
        "\n",
        "llm_model"
      ],
      "id": "db449e13fd23ffda",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:12:58.593251Z",
          "start_time": "2025-05-15T12:12:58.578834Z"
        },
        "id": "23fe444377f312a5"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Get the compute capability of the first CUDA device\n",
        "device_capability = torch.cuda.get_device_capability(0)[0]\n",
        "print(device_capability)"
      ],
      "id": "23fe444377f312a5",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:12:58.711840Z",
          "start_time": "2025-05-15T12:12:58.631276Z"
        },
        "id": "e70f9a95bd245ae4"
      },
      "cell_type": "code",
      "source": [
        "input = \"What are macro nutrients and what roles do they play in the human body\"\n",
        "print(f\"Input text : {input}\")\n",
        "\n",
        "dialogue_template = [\n",
        "    {\"role\" : \"user\",\n",
        "     \"content\" : input}\n",
        "]\n",
        "\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(\n",
        "    conversation = dialogue_template,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt = True\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"\\n Prompt Template (formatted) :\\n {prompt}\")"
      ],
      "id": "e70f9a95bd245ae4",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:12:58.896480Z",
          "start_time": "2025-05-15T12:12:58.867743Z"
        },
        "id": "79442d93073391a3"
      },
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
        "print(\"Vocab size:\", tokenizer.vocab_size)\n",
        "print(\"Input IDs:\", tokenized['input_ids'])\n",
        "print(\"Max token ID in input:\", tokenized['input_ids'].max())\n"
      ],
      "id": "79442d93073391a3",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:12:59.133851Z",
          "start_time": "2025-05-15T12:12:59.057414Z"
        },
        "id": "d127e55e0475b906"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
      ],
      "id": "d127e55e0475b906",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:12:59.345042Z",
          "start_time": "2025-05-15T12:12:59.310696Z"
        },
        "id": "6a07fee6de87b030"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "import torch\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "\n",
        "# your previous code\n",
        "input_ids = tokenizer.apply_chat_template(\n",
        "    conversation=dialogue_template,\n",
        "    return_tensors=\"pt\",\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "# Check if token IDs are within the vocab size range\n",
        "assert input_ids.max() < tokenizer.vocab_size, \"Token IDs exceed vocab size\"\n",
        "\n",
        "# Move to GPU\n",
        "input_ids = input_ids.to(\"cuda\")\n",
        "\n",
        "print(f\"Input IDs shape: {input_ids.shape}\")\n",
        "print(f\"Max token ID: {input_ids.max()}\")\n",
        "print(f\"Min token ID: {input_ids.min()}\")\n",
        "print(f\"Vocab size: {tokenizer.vocab_size}\")\n",
        "print(f\"Full tensor: {input_ids}\")\n"
      ],
      "id": "6a07fee6de87b030",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-15T12:15:52.595108Z",
          "start_time": "2025-05-15T12:15:51.702138Z"
        },
        "id": "37b00b33c6aad809"
      },
      "cell_type": "code",
      "source": [],
      "id": "37b00b33c6aad809",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "3bdb4d7cccf5a9d7"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [],
      "id": "3bdb4d7cccf5a9d7"
    },
    {
      "metadata": {
        "id": "76f7603f38f7f277"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [],
      "id": "76f7603f38f7f277"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}